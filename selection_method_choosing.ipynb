{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this code work, the Google word2vec model must be downloaded : GoogleNews-vectors-negative300.bin.gz : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "val = pd.read_csv('data/validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train = pd.concat([train, val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained word2vec model\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_vectors = big_train['text'].apply(lambda x: np.mean([model[word] for word in x.split() if word in model.key_to_index], axis=0))\n",
    "article_vectors_2d = np.vstack(article_vectors)\n",
    "title_vectors = big_train['titles'].apply(lambda x: np.mean([model[word] for word in x.split() if word in model.key_to_index], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text'].apply(lambda x: np.mean([model[word] for word in x.split() if word in model.key_to_index], axis=0))\n",
    "y_train = train['titles'].apply(lambda x: np.mean([model[word] for word in x.split() if word in model.key_to_index], axis=0))\n",
    "X_test = val['text'].apply(lambda x: np.mean([model[word] for word in x.split() if word in model.key_to_index], axis=0))\n",
    "y_test = val['titles'].apply(lambda x: np.mean([model[word] for word in x.split() if word in model.key_to_index], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = LinearRegression().fit(np.vstack(X_train.values), np.vstack(y_train.values))\n",
    "reg = MultiOutputRegressor(SVR()).fit(np.vstack(X_train.values), np.vstack(y_train.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.026490344669608454\n",
      "Mean Squared Error (MSE): 0.0011706317107680038\n",
      "Root Mean Squared Error (RMSE): 0.034214495623463514\n",
      "R² score: -0.008839216376161859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# Prédire les valeurs pour le jeu de test\n",
    "y_pred = reg.predict(np.vstack(X_test.values))\n",
    "\n",
    "# Calculer les métriques d'évaluation\n",
    "mae = mean_absolute_error(np.vstack(y_test), y_pred)\n",
    "mse = mean_squared_error(np.vstack(y_test), y_pred)\n",
    "rmse = sqrt(mse) # ou np.sqrt(mse)\n",
    "r2 = r2_score(np.vstack(y_test), y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R² score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best sentence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings_pred = reg.predict(np.vstack(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sentences = []\n",
    "for i, text in enumerate(val['text']):\n",
    "    # Calculer l'embedding pour chaque phrase dans l'article\n",
    "    sentence_embeddings = []\n",
    "    for sentence in text.split('.'):\n",
    "        words = [model[word] for word in sentence.split() if word in model.key_to_index]\n",
    "        if words:  # Vérifier que la liste n'est pas vide\n",
    "            embedding = np.mean(words, axis=0)\n",
    "            # Normaliser l'embedding par la longueur de la phrase\n",
    "            normalized_embedding = embedding / len(sentence)\n",
    "            sentence_embeddings.append(normalized_embedding)\n",
    "    \n",
    "    if sentence_embeddings:  # Vérifier que la liste n'est pas vide\n",
    "        # Calculer la similarité cosinus entre l'embedding du titre prédit et l'embedding de chaque phrase\n",
    "        similarities = cosine_similarity(title_embeddings_pred[i].reshape(1, -1), sentence_embeddings)\n",
    "        \n",
    "        # Sélectionner l'index de la phrase qui a la plus grande similarité cosinus\n",
    "        best_sentence_index = np.argmax(similarities)\n",
    "        \n",
    "        # Ajouter la meilleure phrase à la liste\n",
    "        best_sentences.append(text.split('.')[best_sentence_index])\n",
    "    else:\n",
    "        # Si aucune phrase ne contient de mots dans model.key_to_index, ajouter une chaîne de caractères vide\n",
    "        best_sentences.append('')\n",
    "\n",
    "# Ajouter les meilleures phrases au dataframe de validation\n",
    "val['best_sentence'] = best_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rougeL': 0.1550764405516925}\n"
     ]
    }
   ],
   "source": [
    "scores = [scorer.score(title, best_sentence) for title, best_sentence in zip(val['titles'], val['best_sentence'])]\n",
    "\n",
    "# Calculer les scores moyens\n",
    "mean_scores = {key: np.mean([score[key].fmeasure for score in scores]) for key in scores[0].keys()}\n",
    "\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(a_ngram):\n",
    "    words = a_ngram.split()\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Sur les réseaux sociaux, les images sont impressionnantes. Dimanche matin à Venise, l'équipage du MSC Opéra a perdu le contrôle du paquebot, à son arrivée dans le port de la cité des Doges. Le navire, qui peut contenir plus de 2.600 passagers, est venu heurter le quai auquel il voulait s'arrimer. Le paquebot a raclé le quai sur plusieurs mètres, suscitant la panique des personnes à terre, avant de percuter un autre bateau touristique, le Michelangelo, stoppant ainsi sa course. Des témoins ont filmé la scène. Les vidéos montrent des touristes courant pour tenter de fuir le paquebot, qui ne semble pas vouloir s'arrêter. Quatre personnes ont été blessées dans cet accident : deux légèrement, tandis que les deux autres ont été transportées à l'hôpital pour des examens. L'incident s'est produit à San Basilio-Zaterre, dans le canal de la Giudecca, où de nombreux navires de croisière s'arrêtent pour permettre à leurs passagers de visiter Venise.Selon le quotidien italien Corriere della Serra, cette course folle serait due aux forts courants et à la rupture de l'un des câbles qui reliait le navire au remorqueur, qui l'aidait à entrer dans le canal.\",\n",
       "       'La vidéo est devenue virale. Elle montre un policier semblant tirer quasiment à bout portant sur des manifestations avec un lanceur de balles de défense (LBD) lors d\\'échauffourées survenues jeudi, pendant le défilé contre la réforme des retraites. L\\'enquête a été ouverte pour \"violences volontaires par personne dépositaire de l\\'autorité publique\", selon le parquet, et a été confiée à l\\'IGPN, la \"police des polices\". Cette vidéo de 37 secondes montre l\\'avancée des forces de l\\'ordre rue Saint-Lazare, à Paris, qui repoussent les manifestants, principalement à coups de tonfa (une matraque avec une poignée), avant qu\\'un policier équipé d\\'une arme semblant être un LBD ne tire sur la foule à environ un mètre de distance. Les images montrent ensuite un homme à terre. Dans une déclaration à l\\'AFP, la préfecture de police a qualifié cette vidéo de \"parcellaire et sortie de son contexte\", celui de \"violents heurts\" dans le secteur de la gare Saint-Lazare pendant la manifestation. \"Les policiers et les gendarmes ont été pris à partie par des personnes violentes et ont riposté avec des moyens intermédiaires, lacrymogènes et lanceurs de balles de défense\", a précisé la préfecture. \"Au cours de cette manœuvre, 16 membres des forces de l\\'ordre ont été blessés\" et \"aucune plainte pour une personne blessée par un tir de LBD n\\'a été à ce jour portée à la connaissance de la préfecture de police\", conclut le communiqué.',\n",
       "       'Depuis la présidentielle, il est parfois un peu gêné de cette notoriété qui ne se traduira pas forcément dans les urnes. En meeting, le socialiste doit repréciser, non sans humour, l\\'enjeu du scrutin de dimanche. \"Je ne suis pas candidat pour être délégué de classe, mais député\", plaisante Benoît Hamon. Pour lui, c\\'est loin d\\'être gagné. À la présidentielle, Benoît Hamon n\\'est arrivé qu\\'en quatrième position sans sa propre circonscription.Il maintient sa ligne d\\'opposition claire à Emmanuel Macron. \"Une fois qu\\'on a vu qu\\'Emmanuel Macron savait serrer les mains, ce qui n\\'a pas empêché que les États-Unis sortent des accords de Paris, maintenant on rentre dans le dur, le droit du travail\", assure le candidat PS. Mais à Trappes, ce n\\'est pas Emmanuel Macron la cible principale, mais bien Benoît Hamon. Le Républicain Jean-Michel Fourgous, qu\\'il avait battu en 2012, ne rêve que de revanche. Benoît Hamon est aussi attaqué sur son flanc gauche avec le candidat de la France insoumise Mathurin Lévis. Jean-Luc Mélenchon est arrivé deuxième à la présidentielle dans la circonscription. Au total, ils sont 12 candidats à vouloir détrôner Benoît Hamon.',\n",
       "       ...,\n",
       "       '\"Pas possible... les Insoumis préfèrent le café chaud au café facho\", a-t-il simplement posté sur Twitter. Un message qui ressemble à un non catégorique de la part du camp de Jean-Luc Mélenchon. \"J\\'aimerais bien prendre un café avec Laurent Wauquiez, pourquoi pas avec Mélenchon, pourquoi pas avec d\\'autres. Mais qu\\'on soit constructifs, tout en ne niant pas nos divergences qui sont parfois très importantes\", avait plaidé sur France Info Florian Philippot. Des arguments loin d\\'avoir convaincu la France Insoumise. De son côté, Laurent Wauquiez n\\'a dans l\\'immédiat pas répondu à l\\'invitation.',\n",
       "       'Après l\\'annonce choc du géant japonais du pneumatique Bridgestone de fermer le site de Béthunes dans les Hauts-de-France, le président de la région Xavier Bertrand a indiqué avoir \"rencontré le Premier ministre en tête à tête à Matignon\". \"Le premier dossier dont je lui ai parlé c\\'est Bridgestone\", a-t-il expliqué sur LCI mardi matin. \"J\\'ai demandé (à Jean Castex) de s\\'impliquer personnellement, d\\'impliquer l\\'ensemble du gouvernement pour (...) qu\\'on puisse obtenir un vrai dialogue avec les Japonais\" car \"ils doivent savoir la façon dont se comporte la direction européenne de Bridgestone\", a poursuivi l\\'ancien ministre. Selon ses dires, le chef du gouvernement aurait répondu \"qu\\'il était prêt à s\\'engager\". \"Le Premier ministre a effectivement vu Xavier Bertrand lors d\\'un dîner privé hier soir (lundi soir), rendez-vous prévu de longue date\", a-t-on confirmé dans l\\'entourage de Jean Castex. Les deux hommes se connaissent de longue date puisque l\\'actuel Premier ministre fut conseiller de Xavier Bertrand, quand ce dernier était ministre de la Santé puis du Travail sous la présidence de Jacques Chirac puis Nicolas Sarkozy.Le dossier brûlant de la fermeture de ce site qui emploie 863 salariés est suivi \"personnellement de près, depuis plusieurs semaines\" par le chef du gouvernement, a indiqué son entourage, en soulignant que \"tous les efforts sont mis en œuvre par le gouvernement avec Elisabeth Borne et Agnès Pannier-Runacher pour soutenir l\\'entreprise et ses salariés\".La fermeture, la \"seule option\" pour BridgestoneDe son côté, la ministre déléguée à l\\'Industrie Agnès Pannier-Runacher, qui a participé lundi à une réunion de crise avec des élus locaux et la direction Europe du groupe, a indiqué mardi sur franceinfo que les dirigeants de Bridgestone \"sont prêts à rouvrir des scénarios alternatifs pour remettre de l\\'activité dans l\\'usine\" de Béthune, \"c\\'est clairement établi\".\"Ce qui n\\'empêche pas qu\\'ils ont une conviction sur le fait qu\\'ils ne sont pas capables de produire des pneus dans cette usine dans les conditions actuelles du marché du pneu en Europe\", a-t-elle ajouté, expliquant que \"tout l\\'enjeu\", désormais, était de \"contre-expertiser leur propre analyse\". Pour ce faire, \"nous avons mandaté un expert, Accenture, pour regarder les données de Bridgestone\", a-t-elle indiqué. \"Ce qui nous importe, c\\'est d\\'avoir de l\\'emploi industriel à Béthune pour ces salariés-là\", a-t-elle souligné.La direction de Bridgestone a estimé mardi dans un communiqué que la fermeture du site de Béthune était \"la seule option\", mais qu\\'elle entendait \"participer activement à la recherche de solutions pour le site et le territoire\".Une loi pour conditionner les aides d\\'EtatL\\'exemple de Bridgestone à Béthune montre la nécessité d\\'une loi qui permettrait d\\'exiger le remboursement des aides publiques versées à des entreprises qui ne \"jouent pas le jeu\" du maintien de leurs activités, a plaidé de son côté le secrétaire général de la CFDT, Laurent Berger. \"Il faut enfin qu\\'on soit un peu moins naïf, un peu moins impuissant et qu\\'on puisse dans ces cas-là avoir une législation qui permette de demander des comptes à l\\'entreprise\", a souligné le responsable syndicaliste mardi matin sur Europe 1.A Béthune, au fil des années, la direction de l\\'usine Bridgestone a organisé elle-même la fuite de son activité\" vers d\\'autres sites industriels, a observé le syndicaliste. \"Lorsqu\\'une entreprise ne joue pas le jeu du maintien de son activité\", il faut \"qu\\'elle rembourse les aides\", a-t-il poursuivi, regrettant l\\'absence actuelle d\\'un \"cadre législatif\" pour l\\'y contraindre.L\\'utilisation des aides publiques \"doit être conditionnée à un accord\" du comité social et économique (CSE), a encore insisté le numéro un de la CFDT. L\\'adoption d\\'une telle loi aurait lieu \"sans doute trop tard pour Bridgestone mais il ne faut pas que ça puisse se reproduire\", a-t-il plaidé.',\n",
       "       'C\\'est son frère Jean-François qui vient de nous quitter comme le révèle Le Courrier Picard. A l\\'âge de 74 ans, c\\'est une longue maladie qui l\\'aurait emporté. Il n\\'était pas seulement le frère de Jean-Pierre Pernaut. A Amiens, c\\'est sa brillante carrière de médecin généraliste qui faisait sa notoriété, mais aussi sa passion pour le hockey sur glace. C\\'est donc avec émotion que le Hockey Club Amiens a confirmé sa disparition sur sa page Facebook. \"C\\'est avec une immense tristesse que nous venons d\\'apprendre le décès de Jean-François Pernaut. Il aura été pendant plus de 25 ans l\\'emblématique Doc des Gothiques d\\'Amiens et un ami pour tous celles et ceux qui gravitent autour du hockey amiénois. Nous adressons à ses proches nos plus sincères condoléances dans ces moments douloureux\", peut-on lire. Un message qui apaisera peut-être la douleur du journaliste'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(ngram):\n",
    "    words = ngram\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traiter(liste,n):\n",
    "    new_list = [liste[0]]\n",
    "    for candidat in liste[1:]:\n",
    "        if abs(candidat-new_list[-1])>n:\n",
    "            new_list.append(candidat)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 55]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traiter([1,2,55],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_meilleurs_ngrams(k,n):\n",
    "    n = 4  # pour les bigrammes\n",
    "    articles_words = [[sentence.split() for sentence in article.split('.')] for article in val['text'].values]\n",
    "    article_ngrams = [[[ngram for ngram in ngrams(words, n)] for words in article] for article in articles_words]\n",
    "    title_embeddings = reg.predict(np.vstack(X_test.values))\n",
    "    article_ngram_embeddings = [[[get_embedding(ngram) for ngram in sentence] for sentence in article] for article in article_ngrams]\n",
    "    similarities = [[[cosine_similarity([ngram_embedding], [title_embedding]) for ngram_embedding in sentence] for sentence in article] for article, title_embedding in zip(article_ngram_embeddings, title_embeddings)]\n",
    "    flat_similarities = [np.array([sim for sentence in article for sim in sentence]) for article in similarities]\n",
    "    flat_similarities2=[]\n",
    "    for article in flat_similarities:\n",
    "        flat_similarity2 = []\n",
    "        for the_list in article:\n",
    "            flat_similarity2.append(the_list[0][0])\n",
    "        flat_similarities2.append(flat_similarity2)\n",
    "    flat_articles_ngrams = [np.array([sim for sentence in article for sim in sentence]) for article in article_ngrams]\n",
    "    best_ngrams_indices = []\n",
    "    i=0\n",
    "    for article_sim in flat_similarities2 :\n",
    "        indices = np.argsort(article_sim)[-k:]\n",
    "        best_ngrams_indices.append(indices)\n",
    "    concatenation = []\n",
    "    for i in range(0,len(best_ngrams_indices)):\n",
    "        les_indices = best_ngrams_indices[i]\n",
    "        concat = ''\n",
    "        les_indices = traiter(les_indices,n)\n",
    "        for indice in les_indices :\n",
    "            concat += ' '.join(flat_articles_ngrams[i][indice])\n",
    "            concat += '. '\n",
    "        concatenation.append(concat)\n",
    "    return(concatenation)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(k,n):\n",
    "    scores = [scorer.score(title, best_sentence) for title, best_sentence in zip(val['titles'], k_meilleurs_ngrams(k,n))]\n",
    "    mean_scores = {key: np.mean([score[key].fmeasure for score in scores]) for key in scores[0].keys()}\n",
    "    return(mean_scores['rougeL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07448655981309939\n",
      "0.10407554334497263\n",
      "0.12282542913020117\n",
      "0.13361844033354958\n",
      "0.14130069967109968\n",
      "0.14606026356860674\n",
      "La meilleure valeur de score est 0.14606026356860674 avec k = 6 et n = 1\n"
     ]
    }
   ],
   "source": [
    "best_score = -float('inf')\n",
    "best_k, best_n = None, None\n",
    "\n",
    "for k in range(1, 7):\n",
    "    for n in range(1, 7):\n",
    "        current_score = score(k, n)\n",
    "        if current_score > best_score:\n",
    "            print(current_score)\n",
    "            best_score = current_score\n",
    "            best_k, best_n = k, n\n",
    "\n",
    "print(f\"La meilleure valeur de score est {best_score} avec k = {best_k} et n = {best_n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextlp-u36LKDwz-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
